{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JIFs: 15232; Abs: 6335\n"
          ]
        }
      ],
      "source": [
        "# Read all columns and concatenate them into a single dataframe\n",
        "JIF_df = pd.read_csv(f\"IFs_df.csv\", header = 0, sep=\"\\t\", index_col=0)\n",
        "Abs_df = pd.read_csv(f\"abstracts_df.csv\", header = 0, sep=\"\\t\", index_col=0)\n",
        "print(f'JIFs: {len(JIF_df)}; Abs: {len(Abs_df)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6302"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Join files on ISSN, drop duplicates\n",
        "new_df = pd.merge(JIF_df, Abs_df[Abs_df['ISSN'].notna()], how = 'right', on=['ISSN', 'Year Published'])\n",
        "new_df.drop_duplicates(subset=['Document Title'], keep='first', inplace=True, ignore_index=True)\n",
        "# Join files on eISSN, drop duplicates\n",
        "new_df_1 = pd.merge(JIF_df, Abs_df[Abs_df['ISSN'].isna()], how = 'right', on=['eISSN', 'Year Published'])\n",
        "new_df_1.drop_duplicates(subset=['Document Title'], keep='first', inplace=True, ignore_index=True)\n",
        "\n",
        "# Conctenate joins, drop extra columns\n",
        "join_df = pd.concat([new_df, new_df_1], axis = 0)\n",
        "join_df.drop(columns = ['eISSN_x', 'eISSN_y', 'ISSN_x', 'ISSN_y'], inplace=True)\n",
        "join_df['Year Published'] = join_df['Year Published'].astype(int)\n",
        "join_df['Publication Name'] = join_df['Publication Name'].apply(lambda x: x.lower())\n",
        "len(join_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop columns irrelevant for the analysis\n",
        "join_df.drop(['Keywords PlusÂ®', 'E-mail Address', 'ResearcherID Number', 'ORCIDs', 'Publisher', 'Publisher City','ISO Source Abbreviation', 'Publication Date',\n",
        "       'Volume', 'Issue', 'Beginning Page', 'Ending Page', 'Journal name',\n",
        "       'Digital Object Identifier (DOI)', 'Author Full Name'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['ISSN', 'JIF', 'Eigenfactor', 'Year Published', 'Authors',\n",
              "       'Document Title', 'Publication Name', 'Author Keywords', 'Abstract',\n",
              "       'Author Address', 'Reprint Address', 'Funding Agency and Grant Number',\n",
              "       'Cited Reference Count', 'Times cited', 'Usage Count (Last 180 Days)',\n",
              "       'Usage Count (Since 2013)', 'Publisher Address', 'Page Count',\n",
              "       'Web of Science Categories', 'eISSN'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "join_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_13688\\2774811435.py:3: FutureWarning: Starting with pandas version 3.0 all arguments of to_csv except for the argument 'path_or_buf' will be keyword-only.\n",
            "  missing.to_csv('missing.csv', '\\t')\n"
          ]
        }
      ],
      "source": [
        "#Find journals with missing JIF\n",
        "missing  = join_df[join_df['JIF'].isna()].groupby(['Publication Name'])['Publication Name'].count().sort_values(ascending=False)\n",
        "missing.to_csv('missing.csv', '\\t')\n",
        "\n",
        "# Now go and manually download the data for missing journals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get a list of files in the missing folder\n",
        "file_list=os.listdir('./raw_data/missing')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assemble a dataframe with the JIFs fo rthe missing publications\n",
        "new_journals = []\n",
        "for file_name in file_list:\n",
        "    file_path= f\"./raw_data/missing/{file_name}\"\n",
        "    with open(file_path) as f:\n",
        "        j_name= f.readline().strip().lower()\n",
        "    df = pd.read_csv(file_path, header = 4, sep=\",\", index_col=False)\n",
        "    df['Publication Name'] = j_name\n",
        "    df['Year'] = pd.to_numeric(df['Year'], errors='coerce')\n",
        "    df.drop(df[df['Journal impact factor'].isna()].index, inplace=True)\n",
        "    df['Year'] = df['Year'].astype(int)\n",
        "    df = df[['Year', 'Journal impact factor', 'Publication Name']]\n",
        "    df.columns = ['Year Published', 'JIF_new', 'Publication Name']\n",
        "    new_journals.append(df)\n",
        "\n",
        "New_IFs_df = pd.concat(new_journals, axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Join the records with missing JIF with the dataframe of the new JIFS\n",
        "new_join_df = pd.merge(New_IFs_df, join_df[join_df['JIF'].isna()], how = 'right', on=['Year Published', 'Publication Name'])\n",
        "new_join_df.drop(['JIF'], axis=1, inplace=True)\n",
        "new_join_df.rename(columns={'JIF_new':'JIF'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4542"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Join the result of the first join and the second join\n",
        "final_join = pd.concat([join_df, new_join_df], axis = 0)\n",
        "final_join.dropna(subset = ['JIF'], inplace=True)\n",
        "final_join.dropna(subset = ['Abstract'], inplace=True)\n",
        "len(final_join)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_13688\\281751105.py:1: FutureWarning: Starting with pandas version 3.0 all arguments of to_csv except for the argument 'path_or_buf' will be keyword-only.\n",
            "  final_join.to_csv('join_df.csv', '\\t')\n"
          ]
        }
      ],
      "source": [
        "final_join.to_csv('join_df.csv', '\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Artem\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "final_join['Abstract'] = final_join['Abstract'].apply(lambda x: [x for x in nltk.sent_tokenize(x) if 'All rights' not in x]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1       The synthesis of the first high specific activ...\n",
              "3       We have developed an efficient and selective r...\n",
              "4       The first selective dopamine D-4 agonist radio...\n",
              "5       Lu-177-PSMA radioligand therapy is a promising...\n",
              "6       [F-18]AZD4694 (2-(2-F-18-fluoro-6-(methylamino...\n",
              "                              ...                        \n",
              "3774    Purpose: The C-X-C chemokine receptor 4 (CXCR4...\n",
              "3776    Recently, promising results of the antitumor e...\n",
              "3793    Introduction Serotonin is involved in a variet...\n",
              "3797    Background Major depressive disorder (MDD) is ...\n",
              "3803    Substance P (SP) is a small peptide commonly k...\n",
              "Name: Abstract, Length: 4542, dtype: object"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_join['Abstract'] = final_join['Abstract'].apply(lambda x: ' '.join(x))\n",
        "final_join['Abstract']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4435"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_join = final_join[final_join['JIF']<20]\n",
        "final_join = final_join[final_join['JIF']>=1]\n",
        "len(final_join)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_13688\\2408464545.py:1: FutureWarning: Starting with pandas version 3.0 all arguments of to_csv except for the argument 'path_or_buf' will be keyword-only.\n",
            "  final_join.to_csv('new_raw_data.csv', '\\t')\n"
          ]
        }
      ],
      "source": [
        "final_join.to_csv('new_raw_data.csv', '\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
