% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}
\usepackage{graphicx}
\usepackage{wrapfig}

% Remove the "review" option to generate the final version.
\usepackage[]{ACL2023}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

\title{Assessing the Impact Score of Scientific Publications through the Analysis of Abstracts and their Metadata}


\author{Artem Lebedev\\
  UC Berkeley / Berkeley, CA \\
  \texttt{artem.lebedev@berkeley.edu} \\\And
 Farouk Ghandour \\
  UC Berkeley / Berkeley, CA \\
  \texttt{fghandour18@berkeley.edu} \\}

\begin{document}
\maketitle
\begin{abstract}
An impact score of the academic paper is a metric critically important for a scientist's career and attraction of funding for future research. The ability to predict the potential score of a paper could help scientists adjust their presentation strategy to achieve maximum impact. Natural language processing (NLP) is a logical tool to examine what leads to a scientific article's strong impact score because it allows one to analyze an article’s content numerically. In this paper we demonstrate the use of sciBERT with a combination of convolutional neural net to predict the impact factor of the paper based on it abstract.
\end{abstract}

\section{Introduction}
% Not done. Supppoesed to describe motivation for the work.
\textbf{Why hypothesis is interesting}. An impact score of the academic paper is a metric critically important for a scientist's career and attraction of funding for future research. The ability to predict the potential score of a paper could help scientists adjust their presentation strategy to achieve maximum impact. Our team aims to elucidate the factors that drive acceptance in high-impact journals. The main challenge of this task is that acceptance of a paper is a product of the interplay between  features of the paper and journal. Statistically speaking, interaction terms in the model have relatively large weights and some interaction terms are likely non-linear.
\textbf{What the hypothesis is.} We hypothesize that most variation in the paper impact can be explained by the meta data for the paper: country of origin, number of authors, length of the paper and so on. In other words, it is likely that addition of the text data will not increase the statistical power of the model. Two metrics of impact are commonly used in evaluation of scientific research: Journal Impact Factor (JIF) and the number of times the paper was cited in the works of others (Citation index). JIF is calculated for the journal as a whole and thus immediately available for all papers and does not change over time. Citation index is specific for the particular paper, and grows with time. In this project we will focus on JIF because of its more uniform distribution, but will attempt to analyze citation index as well. 
We selected Pearson's correlation coefficient between the predicted impact and observed impact as the metric to evaluate and compare models. In the social science context correlation coefficient above 0.5 is generally considered moderately strong\citep{KahnemanDaniel2021N:af}. Following this convention  
% Not done

\section{Background}
% Not done. Supppoesed to describe motivation for the work.
A few attempts have been made to address this issue, demonstrating modest but encouraging success. \citep{Macri2023-tr, Alohali2022-no, 10.1162/qss_a_00258, doi:10.1152/japplphysiol.00489.2020} The most sophisticated model utilized BERT context-aware encoding of the abstract to produce embeddings that were then classified using  SVM, logistic regression or XGBoost to predict the impact factor quintile. This approach demonstrated prediction accuracy of approx. 75%.

\section{Data}
In our work, we will rely on the data extracted from the Web of Science, a paid-access platform that provides access to reference and citation data from academic journals and conference proceedings. The platform allows downloading csv files with the article abstract along with the ISSN identifier of the journal and other metadata. To compose a homogeneous dataset we will focus on a narrow field of radioligand therapy and select only original peer-reviewed articles published between 2000 and 2024. The dataset contains 9137 records and takes up 33MB of disk space. Journal impact factors come from the Claritive Analytics “Journal Impact Factor Report” and contain the journal ISSN as well as the impact factor, by year.
\subsection{ETL}
Short description of how downloaded data was transformed into final dataframe. 
\subsection{EDA}
Appendix~\ref{sec:appendix} will contain full EDA

\begin{figure}
	\includegraphics[width= \columnwidth]{./Images/Pairplot.png}
	\caption{Correlation plot of main numerical features}
	\label{fig:paiplot}
\end{figure}

\section{Methods}
% Not done. Include a description of any proposed work here.
We are planning to use the sciBERT model in combination with a convolutional network to predict the impact factor. SciBERT was trained on a large corpus of scientific text, including biomedical publications, making us hopeful that it will produce better results on our data set. The exact architecture of the model will be determined via experimentation, but we plan to investigate using convolution layers on top of all embedding or separating out sentence-level tokens as a separate input into the final layer, akin to the approach in reference \citep{hs2022}.

\section{Results and discussion}
%For your baseline model, though feel free to include material for anything else you’ve done

\section{Conclusions and Next Steps}
Section for work you plan to do before submitting the final version. IN the final version that is' going be only conclusions.
\begin{figure}
	\includegraphics[width= \columnwidth]{./Images/Countries.png}
	\caption{Countries of authors and publishers}
	\label{fig:countries}
\end{figure}

\section*{Limitations}
While we are open to different types of limitations, just mentioning that a set of results have been shown for English only probably does not reflect what we expect. 
Mentioning that the method works mostly for languages with limited morphology, like English, is a much better alternative.
In addition, limitations such as low scalability to long text, the requirement of large GPU resources, or other things that inspire crucial further investigation are welcome.

% Entries for the entire Anthology, followed by custom entries
\bibliography{custom}
\bibliographystyle{acl_natbib}

\appendix

\section{Example Appendix}
\label{sec:appendix}

This is a section in the appendix.
% This is a table template
\begin{table}
	\centering
	\begin{tabular}{lc}
		\hline
		\textbf{Command} & \textbf{Output}\\
		\hline
		\verb|{\`i}| & {\`i} \\ 
		\verb|{\.I}| & {\.I} \\ 
		\verb|{\o}| & {\o} \\
		\verb|{\aa}| & {\aa}  \\\hline
	\end{tabular}
	\begin{tabular}{lc}
		\hline
		\textbf{Command} & \textbf{Output}\\
		\hline 
		\verb|{\l}| & {\l} \\ 
		\verb|{\~n}| & {\~n} \\ 
		\verb|{\H o}| & {\H o} \\ 
		\verb|{\v r}| & {\v r} \\ 
		\hline
	\end{tabular}
	\caption{Example commands for accented characters, to be used in, \emph{e.g.}, Bib\TeX{} entries.}
	\label{tab:accents}
\end{table}

\end{document}
