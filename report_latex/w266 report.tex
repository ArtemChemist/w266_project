% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{amsmath}

% Remove the "review" option to generate the final version.
\usepackage[]{ACL2023}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

\title{Assessing the Impact Score of Scientific Publications through the Analysis of Abstracts and their Metadata}


\author{Artem Lebedev\\
  UC Berkeley / Berkeley, CA \\
  \texttt{artem.lebedev@berkeley.edu} \\\And
 Farouk Ghandour \\
  UC Berkeley / Berkeley, CA \\
  \texttt{fghandour18@berkeley.edu} \\}

\begin{document}
\maketitle
\begin{abstract}
An impact score of the academic paper is a metric critically important for a scientist's career and attraction of funding for future research. The ability to predict the potential score of a paper could help scientists adjust their presentation strategy to achieve maximum impact. Natural language processing (NLP) is a logical tool to examine what leads to a scientific article's strong impact score because it allows one to analyze an article’s content numerically. In this paper we demonstrate the use of sciBERT with a combination of convolutional neural net to predict the impact factor of the paper based on it abstract.
\end{abstract}

\section{Introduction}
A measurement of the academic paper's impact is critically important for a scientist's career and attraction of funding for future research. The ability to predict the paper's significance could help researchers adjust their presentation strategy to achieve maximum visibility. Our team aims to elucidate the factors that drive acceptance in high-impact journals.

We hypothesize that variation in the impact of an academic paper can be mostly explained by the metadata of the paper: country of origin, number of authors, length of the paper etc. The metrics of impact that is the most amenable for the quantitative analysis is Journal Impact Factor (JIF), wich is, roughly, the average number of times papers in the journals are cited in the works of others.   

We selected Pearson's correlation coefficient between the predicted impact and observed impact as the metric to evaluate and compare models. We will assume that we failed to reject null hypothesis if observed-predicted correlation of the model including text data and metadata is not significantly larger than correlation achieved with the same model lacking text data (Eq.~\ref{eq:hypothesis}).
\begin{equation}\label{eq:hypothesis}
	\begin{cases}
		H_{0}: (r_{w\ text} - r_{only\ metadata}) \leq 0 \\
		H_{A}: (r_{w\ text} - r_{only\ metadata}) > 0\\
	\end{cases}       
\end{equation}
In the social science context correlation coefficient above 0.5 is generally considered moderately positive\citep{KahnemanDaniel2021N:af}. Following this convention, we will consider our findings to be practically significant only if at least one coefficient exceeds 0.5. If both coefficients are below 0.5, it is likely that our research question can not be answered with this data set and our approach. 

\section{Background}
% Not done. Supppoesed to describe motivation for the work.
A few attempts have been made to address this issue, demonstrating modest but encouraging success. \citep{Macri2023-tr, Alohali2022-no, 10.1162/qss_a_00258, doi:10.1152/japplphysiol.00489.2020} The most sophisticated model utilized BERT context-aware encoding of the abstract to produce embedding that were then classified using  SVM, logistic regression or XGBoost to predict the impact factor quintile. This approach demonstrated prediction accuracy of approx. 75%.

\section{Data}
We will rely on the data extracted from the Web of Science, a platform that provides access to citation metrics for the majority of life science publications. The platform allows downloading csv files with the article abstract along with the ISSN identifier of the journal and other metadata. To reduce variability unrelated to the research question we will focus on a narrow field of radioligand therapy and select only original peer-reviewed articles published in English between 2000 and 2024. JIFs are available from Claritive Analytics “Journal Impact Factor Report” and contain the journal ISSN as well as the impact factor, by year. Merging these two datasets on ISSN we achieve our raw dateset, containing approximately 4500 records.

Figure~\ref{fig:paiplot} shows the distribution and correlation matrix for the main quantitative variables available in the metadata
\begin{figure}
	\includegraphics[width= \columnwidth]{./Images/Pairplot.png}
	\caption{Correlation plot of main numerical features}
	\label{fig:paiplot}
\end{figure}
Appendix~\ref{sec:appendix} will contain full EDA

\section{Methods}
% Not done. Include a description of any proposed work here.
We are planning to use the sciBERT model in combination with a convolutional network to predict the impact factor. SciBERT was trained on a large corpus of scientific text, including biomedical publications, making us hopeful that it will produce better results on our data set. The exact architecture of the model will be determined via experimentation, but we plan to investigate using convolution layers on top of all embedding or separating out sentence-level tokens as a separate input into the final layer, akin to the approach in reference \citep{hs2022}.

\section{Results and discussion}
%For your baseline model, though feel free to include material for anything else you’ve done

\section{Conclusions and Next Steps}
Section for work you plan to do before submitting the final version. IN the final version that is' going be only conclusions.
\begin{figure}
	\includegraphics[width= \columnwidth]{./Images/Countries.png}
	\caption{Countries of authors and publishers}
	\label{fig:countries}
\end{figure}

\section*{Limitations}
While we are open to different types of limitations, just mentioning that a set of results have been shown for English only probably does not reflect what we expect. 
Mentioning that the method works mostly for languages with limited morphology, like English, is a much better alternative.
In addition, limitations such as low scalability to long text, the requirement of large GPU resources, or other things that inspire crucial further investigation are welcome.

% Entries for the entire Anthology, followed by custom entries
\bibliography{custom}
\bibliographystyle{acl_natbib}

\appendix

\section{Example Appendix}
\label{sec:appendix}

This is a section in the appendix.
% This is a table template
\begin{table}
	\centering
	\begin{tabular}{lc}
		\hline
		\textbf{Command} & \textbf{Output}\\
		\hline
		\verb|{\`i}| & {\`i} \\ 
		\verb|{\.I}| & {\.I} \\ 
		\verb|{\o}| & {\o} \\
		\verb|{\aa}| & {\aa}  \\\hline
	\end{tabular}
	\begin{tabular}{lc}
		\hline
		\textbf{Command} & \textbf{Output}\\
		\hline 
		\verb|{\l}| & {\l} \\ 
		\verb|{\~n}| & {\~n} \\ 
		\verb|{\H o}| & {\H o} \\ 
		\verb|{\v r}| & {\v r} \\ 
		\hline
	\end{tabular}
	\caption{Example commands for accented characters, to be used in, \emph{e.g.}, Bib\TeX{} entries.}
	\label{tab:accents}
\end{table}

\end{document}
